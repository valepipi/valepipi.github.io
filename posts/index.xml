<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 游泳小狗</title>
    <link>https://valepipi.github.io/posts/</link>
    <description>Recent content in Posts on 游泳小狗</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 12 May 2023 20:52:35 +0800</lastBuildDate><atom:link href="https://valepipi.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RRAM存算一体研究</title>
      <link>https://valepipi.github.io/posts/reram%E5%AD%98%E7%AE%97%E4%B8%80%E4%BD%93/</link>
      <pubDate>Fri, 12 May 2023 20:52:35 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/reram%E5%AD%98%E7%AE%97%E4%B8%80%E4%BD%93/</guid>
      <description>RRAM存算一体研究复旦大学芯片与系统前沿技术论坛-Processing in memory hardcore design and soft landing-北京大学 燕博南 B站教程-存算一体存储器基础(思维导图对发展现状总结详尽) 陈巍谈芯 https://zhuanlan.zhihu.com/p/480612865 **[视频]** 《存算一体白皮书2022》中国移动研究院 冯诺依曼瓶颈与存储墙&amp;hellip;
存算一体的优势模拟存算 PIM优势模拟存算
存算一体研究现状B站教程-存算一体存储器基础(思维导图对发展现状总结详尽) //思维导图 &amp;hellip;
基于PIM的存储器层次结构PIM memory hierarchy
PIM Solution Stack在原有的存储芯片上加计算单元 在SOC上加PIM加速器 //待画图 STACK1 // 待画图 STACK2
存算一体的基本电路模块PIM基本电路模块
存算一体设计难点&amp;hellip;
模拟存内计算的设计挑战挑战主要在模拟计算，数字计算较少。
模拟PIM挑战
优化方向优化方向-可重构 &amp;hellip; 分形冯诺依曼&amp;hellip;</description>
    </item>
    
    <item>
      <title>Transformer Pytorch 源码阅读</title>
      <link>https://valepipi.github.io/posts/transformer/</link>
      <pubDate>Fri, 12 May 2023 10:43:59 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/transformer/</guid>
      <description>Transformer Pytorch 源码阅读论文：https://arxiv.org/pdf/1706.03762.pdf 代码：torch/nn/modules/transformer.py 教程：http://nlp.seas.harvard.edu/2018/04/03/attention.html
!model</description>
    </item>
    
    <item>
      <title>🔗 LeetCode链表题解 (C&#43;&#43;)</title>
      <link>https://valepipi.github.io/posts/leetcode-linklist-c&#43;&#43;/</link>
      <pubDate>Tue, 09 May 2023 09:45:06 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/leetcode-linklist-c&#43;&#43;/</guid>
      <description>本文为链表的Leetcode刷题记录。
参考资料: labuladong
🔗 &amp;lt;链表&amp;gt; 题目列表&amp;hellip;
题解单链表节点定义
struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} ListNode(int x) : val(x), next(nullptr) {} ListNode(int x, ListNode *next) : val(x), next(next) {} }; 21.合并两个有序链表//简单
dummy
class Solution { public: ListNode* mergeTwoLists(ListNode* list1, ListNode* list2) { ListNode* dummy = new ListNode(-1); ListNode* p = dummy; ListNode* p1 = list1; ListNode* p2 = list2; while(p1 != nullptr &amp;amp;&amp;amp; p2 !</description>
    </item>
    
    <item>
      <title>🌴 LeetCode二叉树题解 (C&#43;&#43;)</title>
      <link>https://valepipi.github.io/posts/leetcode-%E4%BA%8C%E5%8F%89%E6%A0%91-c&#43;&#43;/</link>
      <pubDate>Sun, 07 May 2023 14:26:59 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/leetcode-%E4%BA%8C%E5%8F%89%E6%A0%91-c&#43;&#43;/</guid>
      <description>本文为二叉树和二叉搜索树的Leetcode刷题记录。
参考资料: labuladong
🌴 &amp;lt;二叉树&amp;gt; 题目列表力扣题目 知识点 难度 104. 二叉树的最大深度 遍历 简单 543. 二叉树的直径 遍历 简单 144. 二叉树的前序遍历 遍历 简单 226. 翻转二叉树 遍历 简单 114. 二叉树展开为链表 递归 中等 116. 填充每个节点的下一个右侧节点指针 遍历三叉树 中等 105. 从前序与中序遍历序列构造二叉树 递归构造 中等 106. 从中序与后序遍历序列构造二叉树 递归构造 中等 889. 根据前序和后序遍历构造二叉树 递归构造(结果不唯一) 中等 654. 最大二叉树 递归构造 中等 652. 寻找重复的子树 后序遍历 中等 337. 打家劫舍 III 遍历 中等 236. 二叉树的最近公共祖先 递归 中等 222. 完全二叉树的节点个数 递归 中等 297. 二叉树的序列化与反序列化 递归 困难 题解二叉树结点定义</description>
    </item>
    
    <item>
      <title>How to OpenMP</title>
      <link>https://valepipi.github.io/posts/how-to-openmp/</link>
      <pubDate>Fri, 24 Feb 2023 23:32:39 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/how-to-openmp/</guid>
      <description>介绍fork-join模式的并行编程库， 操作线程单位， 线程级别并行
用类似于 #pragma omp parallel num_threads(8) 的制导语句指定程序中的并行区域
安装在ubuntu自带的build-essential包中, 查看openmp版本：
echo |cpp -fopenmp -dM |grep -i open #define _OPENMP 201511 编译使用直接在编译语句添加-fopenmp g++ -02 -std=c++4 -fopenmp hello.cpp -o hello 或者修改项目的task.json, 在args中加入&amp;quot;-fopenmp&amp;quot; &amp;#34;tasks&amp;#34;:[ { &amp;#34;args&amp;#34;: [ &amp;#34;-fdiagnostics-color=always&amp;#34;, &amp;#34;-fopenmp&amp;#34;, &amp;#34;-g&amp;#34;, &amp;#34;${file}&amp;#34;, &amp;#34;-o&amp;#34;, &amp;#34;${fileDirname}/${fileBasenameNoExtension}&amp;#34; ], } ] 常用的库函数// 设置并行区运行的线程数 void omp_set_num_threads(int) // 获得并行区运行的线程数 void omp_get_num_threads(int) // 获得线程编号 void omp_get_thread_num(void) // 获得openmp wall clock时间(秒) void omp_get_wtime(void) // 获得omp_get_wtime时间精度 void omp_get_wtick(void) 常用语法变量构造并行</description>
    </item>
    
    <item>
      <title>上帝视角看GPU</title>
      <link>https://valepipi.github.io/posts/gpu/</link>
      <pubDate>Tue, 31 Jan 2023 13:12:36 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/gpu/</guid>
      <description>GPU VS CPUCPU：擅长在小数据上做复杂的串行计算和逻辑控制 GPU：擅长在大量数据上做简单的并行计算 图形流水线：游戏、图形 计算流水线：机器学习 CPU上的Core：CPU和GPU对于Core的概念不同，所以数量的统计方式也不同；如果CPU上的Core数量是道路的数量，那么GPU上的Core数量则是道路上的车道数 GPU上的Core：流处理器SP(Streaming Processor) GPU上的SM(Streaming multi-processor)：一组SP+控制器+片上内存 CPU主存DDR带宽：32 ~ 64 bits，延迟低 GPU显存GDDR带宽：128 ~ 512 bits，高吞吐，但是延迟也高 从GPU读取数据会通过warp调度器，合理调度多个warp的I/O和计算，可以用计算掩盖延迟
图形流水线基础待处理的图形/物体以会切分成三角形表示
帧缓存(Frame Buffer)：其中的内容与显示器上的每个像素一一对应，每三个分量(RGB)代表一个像素(Pixel)
显卡(Graphics Card)：把帧缓存中的内容转化成显示信号，输出到显示器上，它是没有计算能力的
Shader：专门用来渲染图形的可编辑程序，通过shader，可以自定义显卡渲染画面的算法。其中，Vertex Shader（顶点着色器）主要负责顶点的几何关系等的运算，Pixel Shader（像素着色器）主要负责片源颜色等的计算，需要进行纹理采样。现在发展为unified Shader，统一架构来整合这两种Shader底层的硬件资源。
可编程流水线单元 PPU(Programmable Pipeline Unit)：和GPU/CPU同等地位，用于图像的计算处理，可以绑上Shader程序进行特殊的计算
纹理(Texture)：图像的表示
光栅化器(Rasterizer)：实时渲染的关键，输入几何图形，进行光栅化处理(立即式、tile-based)，计算这个图形占据了哪些像素，输出像素
逻辑上的模块划分GPU中可以包含各种专用的模块，作为流水线中独立的部分，这些模块之间不能相互调用，需要通过Texture buffer交互
参考资料https://www.bilibili.com/video/BV1P44y1V7bu/?spm_id_from=333.999.0.0 </description>
    </item>
    
    <item>
      <title>ReRAM存算一体加速CNN</title>
      <link>https://valepipi.github.io/posts/reram%E5%8A%A0%E9%80%9Fcnn/</link>
      <pubDate>Mon, 30 Jan 2023 16:06:16 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/reram%E5%8A%A0%E9%80%9Fcnn/</guid>
      <description>ReRAM器件特性ReRAM 是一种无源双端型阻性器件，可储存多个阻态(MLC)。
存储模式VS计算模式：一般的，ReRAM 阵列在进行计算操作时需要将所有的输入端口打开。
优势可作为存储元件，将数据以电阻/电导的形式储存在器件中；
可以依据欧姆定律作为模拟计算元件，实现电导与电压相乘的运算。而 ReRAM交叉阵列结构使得同一列的输出电流能够直接在位线上汇聚，与乘累加运算相匹配，凭借这种原理 ReRAM 阵列可以直接在存储本地实现矩阵-向量乘法运算，突破了传统 CPU 存算分离的架构。
缺点多值存储不稳定：目前 ReRAM 器件工艺还不成熟，多阻态之间的阈值区间间隔不大，导致 ReRAM 作为多阻态器件不稳定，目前已有 的基于 ReRAM 的神经网络研究都是将 ReRAM 当作**单比特器件(SLC)**来使用
写入比读取开销大得多：不同于传统存储器件，ReRAM 的阻 变机制导致其读写操作的延时和能耗严重不均衡，对于 ReRAM 多值器件来说，写 操作所需的时间长、输入电压大，写操作的延时和能耗是读操作的 10 倍以上。
ReRAM加速器与其他模块的关系：
ReRAM加速神经网络的关键问题不能直接支持超大规模卷积神经网络(如，三维神经网络)的高能效运算： 相比于二维卷积神经网络，三维卷积神经网络需要的参数量和训练所需的内存容量呈指数倍增长，而将三维卷积神经网络映射到二维 ReRAM 阵列会使阵列面积大幅增加，从而导致串扰等现象更加严重，影响算法的精度。 包含以下两个关键问题： 如何将 卷积核运算转换为适合 ReRAM 计算结构处理的矩阵-向量乘法运算，并使得该转 换引入尽可能少的额外数据传输代价 如何高能效的将多比特神经网络权重值存储到单比特 ReRAM 器件 CNN中运算的大量数据迁移CNN末端的全连接层：需要读取大量的权重矩阵，并与该层的输入向量进行矩阵-向量乘法运算。(得到的输出向量既可直接作为识别结果输出， 又可以通过非线性神经元函数作为下一个全连接层的输入向量。)
CNN中的卷积核运算(占比95%以上)：由于卷积核的每一个元素都是训练得到的神经网络参数，因此卷积核运算中需要反复从存储数据中读取卷积核参数，并与输入特征图进行卷积运算。
CNN卷积核运算映射到二维ReRAM卷积核运算：将两个三维矩阵中的对应元素进行乘加运算；如果将两个三维矩阵按照相同顺序进行完全地展开，那么卷积运算就可以看作为 向量的内积运算。
基于矩阵-向量乘法运算的原理，有两种可能实现的卷积运算映射方法：
特征图数据作为电导值写入到 ReRAM 阵列单元中，卷积核作为 ReRAM 阵列端口的输入电压向量：
可将相同卷积核对应的不同滑窗位置的特征图数据映射到多个 ReRAM 列中，这样可以在同一时钟周期下计算出不同滑窗位置上的卷积结果，而在不同周期下能够计算出多个卷积核的卷积结果。
优点：对于单个特征图的卷积运算有较大的并行度
缺点：(1)进行不同特征图的运算时需要对ReRAM 阵列进行反复擦写，并且写开销远大于读开销; (2)使得神经网络的后一层运算需要等上一层的运算结果写入到 ReRAM 阵列中才能进行运算。</description>
    </item>
    
    <item>
      <title>神经网络基础</title>
      <link>https://valepipi.github.io/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Mon, 30 Jan 2023 14:45:42 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</guid>
      <description>神经网络基本概念神经网络分为两个阶段的运算：训练、推理
训练——过程视角正向传播：目的是使用当前未训练好的网络对训练样本进行推理；过程和推理过程完全一致，包含大量的矩阵-向量乘法运算 反向传播：目的是根据正向传播获得的计算误差，依次计算并存储各层的中间变量以及参数的梯度，包含大量反向的矩阵-向量乘法运算 权重更新：在正向或反向传播的过程中都会进行权重更新，需要计算各权重矩阵的梯度大小，得到权重的更新值，实现模型的更新 推理——结构视角全连接层
卷积层
目的：利用卷积运算的局部特性提取图像的局部特征并逐层抽象 与全连接层的区别：卷积层可以用较少的模型参数实 现对大规模图像的特征提取 特征图(feature map)：在卷积层间传输的特征数据；输入特征图——&amp;gt;卷积核——&amp;gt;输出特征图 卷积核(Convolution Kernel)：卷积核运算是卷积层中的主要运算，涉及大量的数据计算和数据传输。卷积核运算是将两个三维矩阵中的对应元素进行乘法运算，再将乘得的结果进行累加计算。 S为卷积核的行/列的数量，I 为输入特征图的通道数，即一个卷积核的大小为 S×S×I；
假设通道数=1时，一个卷积核在特征图上扫过的面积就是输出结果的size：一个卷积核扫过特征图上的一个区域就得到一个值(size=1*1)，把所有区域的值按照行列拼接起来就是结果(size=扫过的面积)
其他：级联在两层卷积运算中间的辅助运算，如非线性神经元函数(ReLU/Sigmoid)、池化(Pooling)等 非线性神经元函数
目的：提供非线性分类能力，广泛用于传统全连接神经网络、卷积神经网络等各类神经网络算法中 在CNN中，通常级联在卷积核运算后 池化函数
目的：对特征图进行空间压缩,降低特征图的维度 做法：把特征图相邻范围内的所有元素 用一个值替代，从而在保持局部特征的同时，降低卷积神经网络的计算量和参数量 与卷积核运算的区别：池化函数尽管使用与卷积核相同的滑窗形式，在全特征图中进行运算，但是*步长（Stride）*运算形式会令同一个特征图元素不会被包含至多个池化区域内。 形式：平均池化（Mean Pooling）、最大池化（Max Pooling） 相比于平均池化，最大池化更容易保留特征图中最鲜明的特征信息</description>
    </item>
    
    <item>
      <title>cuda编程</title>
      <link>https://valepipi.github.io/posts/cuda/</link>
      <pubDate>Tue, 24 Jan 2023 22:00:57 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/cuda/</guid>
      <description>Cuda并行编程Cuda存储结构Global memory： 可读可写，最大最慢，所有Block共享，通常所说32G的GPU指的是global memory=32G Constant memory: 只读，所有Block共享 Texture memory: 只读，所有Block共享 GPU通过以上三种memory与Host上的memory交互 cudaMemcpy()
Shared memory: 可读可写，很快，较小，一个block内的Thread共享 Local memory: 可读可写，很快，很小，Thread专用 Registers: 可读可写，很快，很小，Thread专用 Cuda线程结构Grid:一组线程块(block) block：一组线程(thread) thread Cuda编程模型的关键术语host: CPU device: GPU host memory: 系统的内存 device memory：gpu卡上的存储器 kernels: GPU函数，由host发出，由device执行 device function: GPU函数，device执行，并且只能被device调用 线程索引如何定位到某一个线程？
计算该线程在所有线程中的索引
一维的线程索引 int index = threadIdx.x + blockIdx.x * M = 5 + 2 * 8 = 21 二维的线程索引 Thread_x = blockIdx.x * blockDim.x +threadIdx.x = 6 Thread_y = blockIdx.</description>
    </item>
    
    <item>
      <title>🐰LeetCode Hot100 题解 (Python)</title>
      <link>https://valepipi.github.io/posts/leetcode/</link>
      <pubDate>Sat, 21 Jan 2023 19:57:59 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/leetcode/</guid>
      <description>😃数学问题1. 两数之和给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。
你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 你可以按任意顺序返回答案。
输入：nums = [2,7,11,15], target = 9 输出：[0,1] 解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。 class Solution: def twoSum(self, nums: List[int], target: int) -&amp;gt; List[int]: &amp;#34;&amp;#34;&amp;#34; 1. 暴力查找O(n^2) 2. 利用dict反查O(n) &amp;#34;&amp;#34;&amp;#34; # n = len(nums) # for i in range(n): # for j in range(i + 1, n): # if nums[i] + nums[j] == target: # return [i ,j] # return [] dict = {} for i in range( len(nums) ): if target - nums[i] not in dict: dict[nums[i]] = i #建立反查表 else: return [dict[target-nums[i]], i] 88.</description>
    </item>
    
    <item>
      <title>SQL题目</title>
      <link>https://valepipi.github.io/posts/sql%E9%A2%98%E7%9B%AE/</link>
      <pubDate>Mon, 27 Jun 2022 18:57:30 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/sql%E9%A2%98%E7%9B%AE/</guid>
      <description>题目1：⛺查询并计算留存率留存率：留存用户数/总用户数 留存用户：第一天登录，且第二天也登录的用户 四舍五入保留3位小数：round(原始数字，3) 根据得到后一天的日期：DATE_ADD(当天日期yy-mm-dd, INTERVAL 1 DAY) 登录的第一天： min(date) Select round(count(distinct user_id)*1.0/(select count(distinct user_id) from login) ,3) from login where (user_id,date) in (select user_id, DATE_ADD(min(date),INTERVAL 1 DAY) from login group by user_id) </description>
    </item>
    
    <item>
      <title>搭建个人博客</title>
      <link>https://valepipi.github.io/posts/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Mon, 27 Jun 2022 18:21:48 +0800</pubDate>
      
      <guid>https://valepipi.github.io/posts/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</guid>
      <description>Hugo+Github搭建博客 参考链接：
Github Pages + Hugo 搭建个人博客
配置主题：
Hugo-Coder主题配置
美化：
插入emoji
更新博客： 先 cd 到 myblog/content 目录下，然后写 md 文章 写好以后，cd 到myblog 下执行 hugo 命令重新生成 public 文件 再cd 进 myblog/public 中，然后执行 git 提交命令提交到 github 即可 # 1.新建一篇文章，在网站根目录：H:\HugoWebsite\blog hugo new posts/测试博客.md # 2.在目录 H:\HugoWebsite\blog\content\posts 下找到对应文件进行修改 # 3.本地预览, http://localhost:1313/ hugo server -D # 4.构建 Hugo 网站 hugo # 5.切换到目录 H:\HugoWebsite\blog\public ，提交修改至本地库 git add . git commit -m &amp;#39;commit info&amp;#39; # 6.将修改推至远程库 git push -u origin master </description>
    </item>
    
  </channel>
</rss>
